{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "img_dim = 28*28\n",
    "batch_size = 64\n",
    "num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(img_dim).to(device)\n",
    "gen = Generator(z_dim, img_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"./dataset/\", transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "optim_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max [ log( D( real ) ) + log( 1 - ( D( G( noise ))))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for batch_idx, (img, _labels) in enumerate(train_loader):\n",
    "        img = img.view(-1, 784)\n",
    "        batch_size = img.shape[0]\n",
    "\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(img).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        optim_disc.step()\n",
    "\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        optim_gen.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noise = torch.randn(1, z_dim).to(device) # Adjust the batch size as needed\n",
    "\n",
    "with torch.no_grad(): # We don't need gradients for inference\n",
    "    generated_image = gen(noise)\n",
    "\n",
    "generated_image = (generated_image + 1) / 2 # Rescale to [0, 1]\n",
    "generated_image = generated_image.squeeze().cpu().numpy().reshape(28,28) # Remove batch dimension and move to CPU\n",
    "\n",
    "plt.imshow(generated_image, cmap='gray') # Assuming the image is grayscale\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2437e-06]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc(torch.tensor(generated_image).view(-1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
